# Quick Reference Guide

## One-Page Cheat Sheet for Model Comparison

### ğŸ¯ Goal
Compare Claude Opus 4.5 vs Llama models for extracting 1008 forms with table alignment issues.

---

## ğŸš€ Quick Start (3 Commands)

```bash
cd /Users/sunny/Applications/bts/jpmorgan/mortgage/modda/backend

# 1. Check setup
python3 test_model_setup.py

# 2. Enable Llama in AWS Console (if needed)
open "https://console.aws.amazon.com/bedrock/home#/modelaccess"

# 3. Run comparison
./run_loan30_comparison.sh
```

---

## ğŸ“ Files You'll Use

### Run Comparisons
```bash
./run_loan30_comparison.sh              # Single loan (Loan 30)
python3 compare_opus_vs_llama.py <pdf>  # Custom PDF
python3 batch_compare_1008.py           # All loans
```

### Check Status
```bash
python3 test_model_setup.py          # Validate API access
python3 list_available_models.py     # List Llama models
```

### Read Documentation
```bash
cat COMPARISON_SUMMARY.md            # Overview (start here)
cat SETUP_INSTRUCTIONS.md            # Detailed setup
cat MODEL_COMPARISON_README.md       # Full usage guide
```

---

## âš™ï¸ Configuration

### Change Llama Model

Edit `compare_opus_vs_llama.py` line 28:

```python
# Current (Llama 3.2 90B Vision)
LLAMA_MODEL_ID = "us.meta.llama3-2-90b-instruct-v1:0"

# Alternatives:
# LLAMA_MODEL_ID = "us.meta.llama3-2-11b-instruct-v1:0"  # Faster
# LLAMA_MODEL_ID = "meta.llama3-3-70b-instruct-v1:0"     # No vision
```

---

## ğŸ“Š Output Location

```
outputs/model_comparison/
â”œâ”€â”€ loan_1579510/                    # Loan 30 results
â”‚   â”œâ”€â”€ report_*.md                  # Human-readable
â”‚   â”œâ”€â”€ comparison_*.json            # Full comparison
â”‚   â”œâ”€â”€ claude_opus_4.5_*.json       # Claude output
â”‚   â””â”€â”€ llama_*_*.json               # Llama output
â””â”€â”€ batch_summary_*.md               # Aggregate stats
```

---

## ğŸ” What to Check in Reports

### 1. Performance (Speed)
```markdown
| Metric | Claude | Llama | Winner |
| Duration | 45s | 38s | LLAMA |
```

### 2. Accuracy (Critical Fields)
```markdown
âœ… total_income: Match ($21,759.79)
âŒ all_other_monthly_payments: Claude=$0, Llama=$1,046
```

### 3. Key Differences
- Focus on "Other Obligations" section
- Check table alignments
- Verify math (totals = sum of parts)

---

## ğŸ› Troubleshooting

### Problem: "Invalid model identifier"
**Solution:** Enable Llama access in AWS Bedrock Console
```
https://console.aws.amazon.com/bedrock/home#/modelaccess
```

### Problem: "No such file"
**Solution:** Check PDF path
```bash
ls ../public/loans/loan_1579510/1008*.pdf
```

### Problem: "Failed to parse JSON"
**Solution:** Check raw response in output file, model may have returned invalid JSON

### Problem: "Timeout"
**Solution:** Increase timeout or try smaller document

---

## ğŸ’° Cost Estimate

| Action | Claude Cost | Llama Cost | Time |
|--------|------------|-----------|------|
| Single 1008 | $0.15 | $0.01 | 1 min |
| 10 loans | $1.50 | $0.10 | 5 min |
| 100 loans | $15.00 | $1.00 | 50 min |

**Potential savings with Llama: 90-95%**

---

## ğŸ“ˆ Decision Matrix

### Use Claude If:
- âœ… Llama accuracy < 90%
- âœ… Table alignment errors
- âœ… Cost is not a concern
- âœ… Need highest quality

### Use Llama If:
- âœ… Accuracy â‰¥ 90%
- âœ… Table alignment good
- âœ… Processing large volumes
- âœ… Cost is important

### Use Hybrid If:
- âœ… Mixed results
- âœ… Different error patterns
- âœ… Want best of both

---

## ğŸ”„ Workflow

```
1. Enable Llama â†’ 2. Test Setup â†’ 3. Run Loan 30 â†’ 4. Review Report
                                        â†“
                              Good results? 
                                   / \
                                YES   NO
                                 â†“     â†“
                        5a. Batch test  5b. Debug/adjust
                                 â†“
                        6. Make decision
                                 â†“
                        7. Update production
```

---

## ğŸ“ Key Files to Edit

### Change model:
`compare_opus_vs_llama.py` (line 28)

### Change prompt:
`compare_opus_vs_llama.py` (function `create_1008_extraction_prompt`)

### Change output:
`compare_opus_vs_llama.py` (function `generate_comparison_report`)

---

## ğŸ“ Help

1. **Setup issues?** â†’ `SETUP_INSTRUCTIONS.md`
2. **Usage questions?** â†’ `MODEL_COMPARISON_README.md`
3. **Model options?** â†’ `LLAMA_MODEL_SETUP.md`
4. **Overview?** â†’ `COMPARISON_SUMMARY.md`
5. **This cheat sheet!** â†’ `QUICK_REFERENCE.md`

---

## âœ… Success Checklist

- [ ] Llama model enabled in AWS
- [ ] `test_model_setup.py` passes all tests
- [ ] Ran comparison on Loan 30
- [ ] Reviewed report
- [ ] Understood differences
- [ ] Made model selection decision

**All checked?** â†’ You're ready for production! ğŸš€

